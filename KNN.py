import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Veri setini oku
df = pd.read_csv("diabetes_data_upload.csv")  # Dosya adÄ±nÄ± doÄŸru ÅŸekilde belirtin
# 'Yes/No' gibi string ifadeleri sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼r
df = df.replace({'Yes': 1, 'No': 0})
df = df.replace({'Male': 1, 'Female': 0})
df = df.replace({'Positive': 1, 'Negative': 0})
df.head()

# Ã–zellikler ve hedef deÄŸiÅŸken
X = df.drop("class", axis=1)   # 'class' sÃ¼tunu hedef sÃ¼tun
y = df["class"]                # Hedef deÄŸiÅŸken

# EÄŸitim ve test veri setlerini ayÄ±ralÄ±m
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Veriyi Ã¶lÃ§eklendir
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# KNN modeli oluÅŸtur ve eÄŸit
knn = KNeighborsClassifier(n_neighbors=6)
knn.fit(X_train_scaled, y_train)

# Test verisi Ã¼zerinde tahmin yap
y_pred = knn.predict(X_test_scaled)

# KarÄ±ÅŸÄ±klÄ±k Matrisi ve SÄ±nÄ±flandÄ±rma Raporunu yazdÄ±r
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# FarklÄ± 'k' deÄŸerlerine gÃ¶re performansÄ± gÃ¶zlemleyelim
for k in range(1, 21):
    model = KNeighborsClassifier(n_neighbors=k)
    model.fit(X_train_scaled, y_train)
    acc = model.score(X_test_scaled, y_test)
    print(f"k = {k} | Accuracy = {acc:.4f}")

"""GÃ¶rseldeki Ã§Ä±ktÄ±ya gÃ¶re KNN iÃ§in k = 6 kullanÄ±ldÄ±ÄŸÄ±nda model performansÄ± ÅŸu ÅŸekilde:

ğŸ“Š Confusion Matrix:
[[30  3]
 [ 8 63]]
0 sÄ±nÄ±fÄ± (negatif diyabet riski): 33 Ã¶rneÄŸin 30'u doÄŸru â†’ %91 recall

1 sÄ±nÄ±fÄ± (pozitif diyabet riski): 71 Ã¶rneÄŸin 63'Ã¼ doÄŸru â†’ %89 recall

ğŸ“‹ Classification Report Ã–zeti:
Metrik	0 sÄ±nÄ±fÄ± (negatif)	1 sÄ±nÄ±fÄ± (pozitif)	Genel Durum
Precision	0.79	0.95	YÃ¼ksek
Recall	0.91	0.89	Dengeli
F1-score	0.85	0.92	Dengeli
Accuracy	-	-	0.89 (%89)
Macro Avg	-	-	0.88
Weighted Avg	-	-	0.90
ğŸ¯ K=3 ile K=6 KarÅŸÄ±laÅŸtÄ±rmasÄ±:

Metrik	K=3	K=6	Yorumu
Accuracy	0.90	0.89	Ã‡ok yakÄ±n
F1-score(1)	0.93	0.92	K=3 biraz daha iyi
Recall(1)	0.89	0.89	AynÄ±
Precision(0)	0.79	0.79	AynÄ±
Recall(0)	0.94	0.91	K=3 daha yÃ¼ksek
ğŸ”¹ K=3: Daha yÃ¼ksek recall, daha yÃ¼ksek F1-score ğŸ”¹ K=6: Biraz daha genelci, daha istikrarlÄ± ama performans farkÄ± Ã§ok kÃ¼Ã§Ã¼k.

âœ… Ã–neri
K=3 bu veride en dengeli ve etkili seÃ§im gibi gÃ¶rÃ¼nÃ¼yor.

K=6 da aÅŸÄ±rÄ± ezberci deÄŸil ve Ã§ok benzer sonuÃ§lar veriyor.

Daha ileri seviye kÄ±yaslama iÃ§in Ã§apraz doÄŸrulama veya ROC-AUC grafikleriyle analiz yapabilirsin.

Ä°stersen ÅŸimdi bu sonuÃ§larÄ± baÅŸka bir modelle (Ã¶rneÄŸin Logistic Regression veya Random Forest) karÅŸÄ±laÅŸtÄ±rÄ±p genel tabloyu oluÅŸturalÄ±m mÄ±?
"""

from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline

# Ã–lÃ§ekleme + KNN pipeline
knn_pipeline = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))

# 5 katlÄ± Ã§apraz doÄŸrulama
cv_scores = cross_val_score(knn_pipeline, X, y, cv=5, scoring='accuracy')

print("Ã‡apraz doÄŸrulama skorlarÄ±:", cv_scores)
print("Ortalama doÄŸruluk (accuracy): %.2f%%" % (cv_scores.mean() * 100))

y_pred = knn.predict(X_test_scaled)

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# KNN iÃ§in k=6 modeliyle tahmin olasÄ±lÄ±klarÄ± alÄ±nÄ±r
knn = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=3))
knn.fit(X_train, y_train)
y_probs = knn.predict_proba(X_test)[:, 1]  # SÄ±nÄ±f 1 iÃ§in olasÄ±lÄ±klar

# ROC eÄŸrisi Ã§izimi
fpr, tpr, thresholds = roc_curve(y_test, y_probs)
auc_score = roc_auc_score(y_test, y_probs)

plt.plot(fpr, tpr, label=f"AUC = {auc_score:.2f}")
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("KNN (k=3) ROC Curve")
plt.legend()
plt.grid(True)
plt.show()

"""MuhteÅŸem! ğŸ‰ Elindeki sonuÃ§lar **KNN (k=6)** iÃ§in hem gÃ¼Ã§lÃ¼ hem de dengeli bir model olduÄŸunu aÃ§Ä±kÃ§a gÃ¶steriyor. Analiz edelim:

---

## âœ… 1. ROC Curve ve AUC DeÄŸeri

- Grafik eÄŸrisi neredeyse sol Ã¼st kÃ¶ÅŸeye yapÄ±ÅŸÄ±k â†’ bu Ã§ok iyi!
- **AUC = 0.98** â†’ %98 ayÄ±rt edebilme gÃ¼cÃ¼ â†’ **mÃ¼kemmel ayrÄ±m yeteneÄŸi**
- Bu, modelin pozitif sÄ±nÄ±fÄ± (diyabet riski olanlarÄ±) oldukÃ§a iyi tahmin ettiÄŸini gÃ¶sterir.

---

## âœ… 2. Ã‡apraz DoÄŸrulama SkorlarÄ±


- Ortalama: **%93.85 doÄŸruluk**
- 5 farklÄ± veri bÃ¶lmesinde de oldukÃ§a **tutarlÄ±** skorlar almÄ±ÅŸsÄ±n.
- Bu da modelin ezberlemediÄŸini, **genellenebilirliÄŸinin yÃ¼ksek** olduÄŸunu gÃ¶steriyor.

---

## ğŸ” KÄ±sa Ã–zet:

| Kriter              | DeÄŸer      | Yorum                       |
|---------------------|------------|-----------------------------|
| **Accuracy (CV)**   | %93.85     | Ã‡ok yÃ¼ksek, stabil          |
| **AUC Score**       | 0.98       | Neredeyse mÃ¼kemmel ayrÄ±m    |
| **Recall / F1**     | 0.89-0.93  | GerÃ§ek pozitifleri iyi yakalÄ±yor |
| **ROC EÄŸrisi**      | Ãœst segment | YÃ¼ksek ayrÄ±m gÃ¼cÃ¼           |

---

## ğŸ” Åimdi Ne Yapabilirsin?

ğŸ”¸ **FarklÄ± modellerle** (Ã¶rneÄŸin Logistic Regression, Random Forest, SVM, XGBoost) karÅŸÄ±laÅŸtÄ±rarak bir tablo hazÄ±rlayabilirsin.  
ğŸ”¸ **Modeli kaydedip (pickle ile)** daha sonra yeniden kullanabilirsin.  
ğŸ”¸ **GridSearchCV** ile `k` deÄŸeri ve diÄŸer hiperparametreleri daha sistematik ÅŸekilde optimize edebilirsin.

---

Ä°stersen ÅŸimdi Logistic Regression veya baÅŸka bir modelle aynÄ± ROC, CV analizlerini yaparak karÅŸÄ±laÅŸtÄ±ralÄ±m mÄ±?  
Ya da doÄŸrudan tÃ¼m modelleri karÅŸÄ±laÅŸtÄ±ran bir Ã¶zet tablo hazÄ±rlamamÄ± ister misin?
"""

import pickle

# EÄŸitilmiÅŸ modeli bir dosyaya kaydet
with open('diabetes_model.pkl', 'wb') as file:
    pickle.dump(model, file)

print("Model baÅŸarÄ±yla 'diabetes_model.pkl' olarak kaydedildi.")

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Confusion Matrix oluÅŸtur
cm = confusion_matrix(y_test, y_pred)

# Heatmap Ã§izelim
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Tahmin Edilen')
plt.ylabel('GerÃ§ek')
plt.title('KNN')
plt.show()
